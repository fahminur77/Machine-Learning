{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tugas 5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HhzCP3ikhlR"
      },
      "source": [
        "PCA example with Iris Data-set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAkQxME3kkia"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import datasets\n",
        "\n",
        "np.random.seed(5)\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "fig = plt.figure(1, figsize=(4, 3))\n",
        "plt.clf()\n",
        "ax = Axes3D(fig, rect=[0, 0, 0.95, 1], elev=48, azim=134)\n",
        "\n",
        "plt.cla()\n",
        "pca = decomposition.PCA(n_components=3)\n",
        "pca.fit(X)\n",
        "X = pca.transform(X)\n",
        "\n",
        "for name, label in [(\"Setosa\", 0), (\"Versicolour\", 1), (\"Virginica\", 2)]:\n",
        "    ax.text3D(\n",
        "        X[y == label, 0].mean(),\n",
        "        X[y == label, 1].mean() + 1.5,\n",
        "        X[y == label, 2].mean(),\n",
        "        name,\n",
        "        horizontalalignment=\"center\",\n",
        "        bbox=dict(alpha=0.5, edgecolor=\"w\", facecolor=\"w\"),\n",
        "    )\n",
        "# Reorder the labels to have colors matching the cluster results\n",
        "y = np.choose(y, [1, 2, 0]).astype(float)\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y, cmap=plt.cm.nipy_spectral, edgecolor=\"k\")\n",
        "\n",
        "ax.w_xaxis.set_ticklabels([])\n",
        "ax.w_yaxis.set_ticklabels([])\n",
        "ax.w_zaxis.set_ticklabels([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGPlQ-dxkna_"
      },
      "source": [
        "Comparison of LDA and PCA 2D projection of Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beFk8F3ClaWV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "target_names = iris.target_names\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_r = pca.fit(X).transform(X)\n",
        "\n",
        "lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "X_r2 = lda.fit(X, y).transform(X)\n",
        "\n",
        "# Percentage of variance explained for each components\n",
        "print(\n",
        "    \"explained variance ratio (first two components): %s\"\n",
        "    % str(pca.explained_variance_ratio_)\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "colors = [\"navy\", \"turquoise\", \"darkorange\"]\n",
        "lw = 2\n",
        "\n",
        "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
        "    plt.scatter(\n",
        "        X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=0.8, lw=lw, label=target_name\n",
        "    )\n",
        "plt.legend(loc=\"best\", shadow=False, scatterpoints=1)\n",
        "plt.title(\"PCA of IRIS dataset\")\n",
        "\n",
        "plt.figure()\n",
        "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
        "    plt.scatter(\n",
        "        X_r2[y == i, 0], X_r2[y == i, 1], alpha=0.8, color=color, label=target_name\n",
        "    )\n",
        "plt.legend(loc=\"best\", shadow=False, scatterpoints=1)\n",
        "plt.title(\"LDA of IRIS dataset\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww9xMypAFibh"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.ensemble import RandomTreesEmbedding, ExtraTreesClassifier\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "# make a synthetic dataset\n",
        "X, y = make_circles(factor=0.5, random_state=0, noise=0.05)\n",
        "\n",
        "# use RandomTreesEmbedding to transform data\n",
        "hasher = RandomTreesEmbedding(n_estimators=10, random_state=0, max_depth=3)\n",
        "X_transformed = hasher.fit_transform(X)\n",
        "\n",
        "# Visualize result after dimensionality reduction using truncated SVD\n",
        "svd = TruncatedSVD(n_components=2)\n",
        "X_reduced = svd.fit_transform(X_transformed)\n",
        "\n",
        "# Learn a Naive Bayes classifier on the transformed data\n",
        "nb = BernoulliNB()\n",
        "nb.fit(X_transformed, y)\n",
        "\n",
        "\n",
        "# Learn an ExtraTreesClassifier for comparison\n",
        "trees = ExtraTreesClassifier(max_depth=3, n_estimators=10, random_state=0)\n",
        "trees.fit(X, y)\n",
        "\n",
        "\n",
        "# scatter plot of original and reduced data\n",
        "fig = plt.figure(figsize=(9, 8))\n",
        "\n",
        "ax = plt.subplot(221)\n",
        "ax.scatter(X[:, 0], X[:, 1], c=y, s=50, edgecolor=\"k\")\n",
        "ax.set_title(\"Original Data (2d)\")\n",
        "ax.set_xticks(())\n",
        "ax.set_yticks(())\n",
        "\n",
        "ax = plt.subplot(222)\n",
        "ax.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, s=50, edgecolor=\"k\")\n",
        "ax.set_title(\n",
        "    \"Truncated SVD reduction (2d) of transformed data (%dd)\" % X_transformed.shape[1]\n",
        ")\n",
        "ax.set_xticks(())\n",
        "ax.set_yticks(())\n",
        "\n",
        "# Plot the decision in original space. For that, we will assign a color\n",
        "# to each point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "h = 0.01\n",
        "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "# transform grid using RandomTreesEmbedding\n",
        "transformed_grid = hasher.transform(np.c_[xx.ravel(), yy.ravel()])\n",
        "y_grid_pred = nb.predict_proba(transformed_grid)[:, 1]\n",
        "\n",
        "ax = plt.subplot(223)\n",
        "ax.set_title(\"Naive Bayes on Transformed data\")\n",
        "ax.pcolormesh(xx, yy, y_grid_pred.reshape(xx.shape))\n",
        "ax.scatter(X[:, 0], X[:, 1], c=y, s=50, edgecolor=\"k\")\n",
        "ax.set_ylim(-1.4, 1.4)\n",
        "ax.set_xlim(-1.4, 1.4)\n",
        "ax.set_xticks(())\n",
        "ax.set_yticks(())\n",
        "\n",
        "# transform grid using ExtraTreesClassifier\n",
        "y_grid_pred = trees.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
        "\n",
        "ax = plt.subplot(224)\n",
        "ax.set_title(\"ExtraTrees predictions\")\n",
        "ax.pcolormesh(xx, yy, y_grid_pred.reshape(xx.shape))\n",
        "ax.scatter(X[:, 0], X[:, 1], c=y, s=50, edgecolor=\"k\")\n",
        "ax.set_ylim(-1.4, 1.4)\n",
        "ax.set_xlim(-1.4, 1.4)\n",
        "ax.set_xticks(())\n",
        "ax.set_yticks(())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}